{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ReconhecimentoDeImagem.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Passo 1 - Vamos importar o TensorFlow"
      ],
      "metadata": {
        "id": "lEHB1kZzBwcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sFw_9SQBzB1",
        "outputId": "af3a46c7-ead4-4c23-bff1-30d45b57dbf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo 2 - vamos carregar o banco de dados Fashion Mnist. O tensorflow disponibiliza este banco de imagens de forma nativa."
      ],
      "metadata": {
        "id": "2KulGSrVCCoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist"
      ],
      "metadata": {
        "id": "t7rrtTTnCThH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo 3 - vamos utilizar a função \"load_data()\" do objeto mnist para carregar os dados. A função load_data já separa dados para treinamento e teste."
      ],
      "metadata": {
        "id": "1QalS8kKCnIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(training_images, training_labels), (test_images,test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "id": "09k4c_URCxOB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5be097e6-2528-497b-82a8-40c4fc624457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos ver a quantidade de imagens que foram carregadas para treinamento, bem como a quantidade de imagens carregadas para teste."
      ],
      "metadata": {
        "id": "i4Yrm3mIJ3Vi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Quantidade de imagens separadas para treinamento:\", len(training_images))\n",
        "print(\"Quantidade de imagens separadas para teste:\", len(test_images))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJLcdqiPJ-Dz",
        "outputId": "bba9a5b7-3e30-4c95-bb62-79daeff26318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidade de imagens separadas para treinamento: 60000\n",
            "Quantidade de imagens separadas para teste: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo 4 - vamos analisar algumas imagens com os respectivos labesl para entendermos no que a máquina se baseia para deduzir qual imagem é o que."
      ],
      "metadata": {
        "id": "PQ5R3HneKRi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(linewidth=200)\n",
        "print(training_images[200])\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(training_images[200])\n",
        "\n",
        "print(\"Label correspondente:\", training_labels[130])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "id": "YzDDBqyRKiv0",
        "outputId": "eb3eb8ef-c59c-40e1-86b3-f339c31579e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0  82 122  37   0   5   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   2   0  38 100  28 121   0   1   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   5   0  86  43   0 136  15   0   2   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   2   0 104  30   0 102  40   0   3   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   3   0   0 111   2   0  73  81   0   4   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   2   0  17  87   0   0  45  81   0   4   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   4   0  54  90   0   0  24  92   0   4   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   3   0  76  30   0   0   0  93   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   0  74   0   0   0   0  86   0   0   1   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 109   0   0   1   0  86  11   0   2   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   2   0  31  79   0   2   2   0 115  38   0   4   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   5   0  66  90   0   1   1   0 136  58   0   5   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   5   0  82 136   0   3   4   0 195  76   0   5   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  95 166   0   0   0   0 144  80   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  45 145 191  20  65  68  40 148 159  79  60   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  70 228 173 214 208 211 215 216 204 204 211 164   3   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  57 176 167 205 199 190 193 195 193 196 183 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 200 186 219 204 191 204 210 204 205 189 184   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 145 170 173 188 202 202 219 211 204 212 198 220   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 174 174 188 192 211 210 215 217 214 219 192 248   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 180 190 175 158 209 209 211 217 215 214 190 249   4   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 184 188 180 210 209 205 218 216 212 208 195 253  16   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 183 201 172 203 206 208 216 215 213 213 196 255  26   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 180 215 184 199 214 219 227 218 219 223 200 228  40   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 187 218 185 206 216 215 221 229 219 218 200 232  53   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 184 207 188 198 217 165 146 214 214 214 200 231  57   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 211 252 229 240 244 252 253 253 250 231 227 245  67   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 109 171 157 163 161 167 160 149 142 145 145 149  11   0   0   0   0   0   0   0]]\n",
            "Label correspondente: 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo 5 - Após analisarmos algumas imagens, vimos que o valor de cada pixel está entre 0 e 255. No entanto, para treinar uma rede neural é conveniente que façamos a normalização dos valores de cada pixel para ficarem entre 0 e 1."
      ],
      "metadata": {
        "id": "ffVADdz_OiZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "#print(training_images[130])"
      ],
      "metadata": {
        "id": "IkiZE_hbO8m8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo 6 - Temos dois conjuntos de imagens: um que será utilizado para treinar o modelo e outro que será utilizado para testar o modelo que foi treinado. Está separação ocorre para evitar o overfitting. Dessa forma, vamos utilizar o conjunto de imagens que estão na variável training_images para treinar a rede neural. Depois, validaremos a acurácia da rede treinado utilizando o conjunto de imagens armazenado na variável test_images.\n",
        "\n",
        "Vamos criar o modelo primeiro e depois vou comentar alguns novos conceitos."
      ],
      "metadata": {
        "id": "s2-ank9iPVik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "                                    ]\n",
        ")"
      ],
      "metadata": {
        "id": "MvMBZifAP19O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comentários relacionados ao model que foi criado.\n",
        "\n",
        "**1. Sequential:** define uma sequência de camadas para a rede neural. É como se criasse um cerébro vazio que receberá N camadas.\n",
        "\n",
        "**2. Flatten:**  lembre-se que as imagens do fashion mnsit possuem resolução 28 x 28. O flatten transforma a matriz que possui 28 linhas e 28 colunas em um array unidimensional de 784 posições. O Flatten \"achata\" a matriz.\n",
        "\n",
        "**3. Dense:** função utilizada para criar uma camada com neurônios. Pode abranger diferentes funções de ativação. **Relu:** se x>0, retorna 1, se não retorna 0. **Softmax:** retorna a probabilidade, os valores variam entre 0 e 1 e correspondem à probabilidade daquele neurônio ser o resultado final. No nosso caso, temos 10 neurônios na última camada porque o dataset possui 10 tipos de roupas distintos."
      ],
      "metadata": {
        "id": "xKvlLK3ESiZR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo 7: agora que as imagens estão normalizadas e que a arquitetura da rede neural está definida, é hora de partirmos para o treinamento da rede neural. iremos definir a quantidade de épocas na qual a rede será treinada e é importante observar que a cada época é possível medir a acurácia do modelo. A acurácia é uma métrica que mede o volume de acertos da rede neural."
      ],
      "metadata": {
        "id": "ZJthiLKpWaik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.optimizers.Adam(),loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCcDu_G6XnrS",
        "outputId": "5f74f8ee-6614-4ae0-ef1c-7ed50e61f902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4995 - accuracy: 0.8247\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3760 - accuracy: 0.8639\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3369 - accuracy: 0.8762\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3132 - accuracy: 0.8862\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2954 - accuracy: 0.8909\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2807 - accuracy: 0.8974\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2673 - accuracy: 0.9014\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2569 - accuracy: 0.9043\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2475 - accuracy: 0.9091\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2390 - accuracy: 0.9108\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faf9cf358d0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo 8 - Uma vez que a rede foi treinada, vamos verificar a acurácia da rede para advinhar as imagens separadas para teste."
      ],
      "metadata": {
        "id": "zUGhDqIJZuip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWLNfeWKZ68e",
        "outputId": "31f80017-181e-4eee-dc61-dc9f4ceec9e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 1ms/step - loss: 0.3359 - accuracy: 0.8827\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.33587655425071716, 0.8827000260353088]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora que o modelo foi treinado, vamos brincar um pouco com a rede neural.\n",
        "O primeiro teste será para vermos a probabilidade elencada para cada saída."
      ],
      "metadata": {
        "id": "AkA59Q4qZuht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(test_images[11])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "e_6NzShI4ffB",
        "outputId": "11fd8e43-22ec-4e8d-9cae-6d49a160b2b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7faf977a3e90>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classificacao = model.predict(test_images)\n",
        "#classificacao[10]\n",
        "for i in range(10):\n",
        "  print(\"%.2f\"%classificacao[10,i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHp0iEMM4sgC",
        "outputId": "2e893af8-aa98-424a-b714-0a05468f119e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.00\n",
            "0.00\n",
            "0.08\n",
            "0.00\n",
            "0.91\n",
            "0.00\n",
            "0.01\n",
            "0.00\n",
            "0.00\n",
            "0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para matar a aula, vamos fazer a ideia do Davi. Vamos treinar a rede até que ela atinja uma acurácia desejada. Neste caso, utilizamos a função callback. A sacada do callback é utilizar como base uma acurácia desejada em detrimento do número de épocas."
      ],
      "metadata": {
        "id": "pOS4xGygDDE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.92):\n",
        "      print(\"\\n Foi atingida a acurácia de 92%, logo, o treinamento será cancelado!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images,test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "                                    ]\n",
        ")\n",
        "\n",
        "model.compile(optimizer=tf.optimizers.Adam(),loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "callback = myCallback()\n",
        "model.fit(training_images, training_labels, epochs=10000, callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I7ozX_7DWHf",
        "outputId": "65100744-d461-4400-8245-1d94f2a08e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5003 - accuracy: 0.8243\n",
            "Epoch 2/10000\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3739 - accuracy: 0.8654\n",
            "Epoch 3/10000\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3377 - accuracy: 0.8767\n",
            "Epoch 4/10000\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3139 - accuracy: 0.8856\n",
            "Epoch 5/10000\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2967 - accuracy: 0.8901\n",
            "Epoch 6/10000\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2842 - accuracy: 0.8946\n",
            "Epoch 7/10000\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2701 - accuracy: 0.8990\n",
            "Epoch 8/10000\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2596 - accuracy: 0.9033\n",
            "Epoch 9/10000\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2481 - accuracy: 0.9071\n",
            "Epoch 10/10000\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2404 - accuracy: 0.9099\n",
            "Epoch 11/10000\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2314 - accuracy: 0.9134\n",
            "Epoch 12/10000\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2259 - accuracy: 0.9161\n",
            "Epoch 13/10000\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2195 - accuracy: 0.9182\n",
            "Epoch 14/10000\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.2120 - accuracy: 0.9202\n",
            " Foi atingida a acurácia de 92%, logo, o treinamento será cancelado!\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2120 - accuracy: 0.9202\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faf978feb90>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos fazer um rede neural convolucional e com pooling para reconhecer as imagens do fashio mnsit"
      ],
      "metadata": {
        "id": "mPr1U8YMP7Mx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images,trainin_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "training_images.reshape(60000, 28, 28, 1)\n",
        "\n",
        "test_images = test_images/255.0\n",
        "test_images.reshape(10000, 28, 28, 1)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Conv2D(64, (3,3), activation = tf.nn.relu, input_shape=(28,28,1)),\n",
        "                                    tf.keras.layers.MaxPooling2D(2,2),\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.optimizers.Adam(),loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USQq3cEBQAsh",
        "outputId": "2fe4104b-5104-45b2-dd6d-41126bb71d3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 54s 29ms/step - loss: 0.3731 - accuracy: 0.8660\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 53s 28ms/step - loss: 0.2503 - accuracy: 0.9089\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 53s 28ms/step - loss: 0.2076 - accuracy: 0.9232\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 52s 28ms/step - loss: 0.1733 - accuracy: 0.9361\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 53s 28ms/step - loss: 0.1458 - accuracy: 0.9454\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faf945bb650>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "id": "uGtHc4bFUEHL",
        "outputId": "4831186c-a133-473a-a3da-d139f3e071dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2513 - accuracy: 0.9143\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2513201832771301, 0.9143000245094299]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}